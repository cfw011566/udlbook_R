---
title: Notebook 2.1 Supervised Learning
author: CF Wang
date: 2025-11-21
format: html
---

```{r}
#| label: setup
#| echo: true
#| fig-width: 8
#| fig-height: 6
#| out-width: 80%
#| fig-align: center
```

```{r}
#| label: Create some input / output data
x <- c(0.03, 0.19, 0.34, 0.46, 0.78, 0.81, 1.08, 1.18, 1.39, 1.60, 1.65, 1.90)
y <- c(0.67, 0.85, 1.05, 1.0, 1.40, 1.5, 1.3, 1.54, 1.55, 1.68, 1.73, 1.6)

print(x)
print(y)
```

```{r}
#| label: Define 1D linear regression model
f <- function(x, phi0, phi1) {
  # Replace this line with the linear regression model (eq 2.4)
  y <- phi0 + phi1 * x
  y
}
```

```{r}
#| label: Function to help plot the data
r_plot <- function(x, y, phi0, phi1) {
  plot(0, xlim = c(0, 2), ylim = c(0, 2),
       xlab = expression(paste("Intput, ", x)),
       ylab = expression(paste("Output, ", y)),
       axes = TRUE, type = "n")
  points(x, y, pch = 16, col = "darkblue")
  # Draw line
  x_line <- seq(0,2, 0.01)
  y_line <- f(x_line, phi0, phi1)

  lines(x_line, y_line, lwd = 2, col = "blue")
}
```

```{r}
#| label: figure 2.2b
#| fig-width: 6
#| fig-height: 6
# Set the intercept and slope as in figure 2.2b
phi0 <- 0.4
phi1 <- 0.2
# Plot the data and the model
r_plot(x, y, phi0, phi1)
```

# Visualizing the loss function

The above process is equivalent to descending coordinate wise on the loss function

Now let's plot that function
